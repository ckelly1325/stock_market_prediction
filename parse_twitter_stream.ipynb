{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Twitter Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to parse the twitter stream files that were downloaded from archive.org, find the tweets related to finance, and create a new file with just those tweets. First the function process_tar_file() is used to extract files from the .tar files that were downloaded, and a folder structure is automatically created from the resulting extract. Next, the process_json() function processes these files, extracting only English language tweets, and saves each day of tweets in a .csv file for easy loading later. Next, a regex filter is used to find only those tweets with a cashtag. Finally, all the filtered tweets are combined and saved into one file.\n",
    "\n",
    "Many of the files were processed individually or in small groups, due to memory limitations on my local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, os, bz2\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import tarfile\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tar_file(tar_file, extract_folder='.'):\n",
    "    \"\"\"\n",
    "    Parses the tar file, obtained from the Twitter Stream Grab from Archive.org, into a structured folder set\n",
    "    with .json.bz2 files for each minute of each hour.\n",
    "    \"\"\"\n",
    "    begin_time = datetime.now()\n",
    "    my_tar = tarfile.open(tar_file)\n",
    "    my_tar.extractall(extract_folder)\n",
    "    my_tar.close()\n",
    "    end_time = datetime.now()\n",
    "    print('Processing complete! Total time:', end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json(directory, outfile):\n",
    "    \n",
    "    \"\"\" \n",
    "    Parses Twitter archives from Archive Team: The Twitter Stream Grab. Tar files must be processed prior to\n",
    "    running this function. Only tweets in the english language are returned. Processed json files are saved to a \n",
    "    csv file, with the name of the outfile parameter and a DataFrame object is also returned with the data\n",
    "    immediately available for use.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    directory: name of the top-level file where the .json.bz2 files were extracted to (from the .tar file)\n",
    "    \n",
    "    outfile: name of the .csv file that the data will be saved to. It is not necessary to add .csv to this.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initializing variables\n",
    "    begin_time = datetime.now()\n",
    "    cursor='>>  '\n",
    "    count_tweets=0\n",
    "    columns=['tweet_date','tweet_id','tweet_text','lang','retweet','tweet_url', 'tweet_reply', 'hashes', 'user_name',\n",
    "             'screen_name', 'user_verified', 'user_lang']\n",
    "    tweet_dict = {}\n",
    "    i = 0 \n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        # Screen prints\n",
    "        clear_output()\n",
    "        print(cursor,'tweets:',count_tweets)\n",
    "        print('-'*10)\n",
    "        print(cursor,'currently searching', dirpath)\n",
    "\n",
    "        for file in filenames:\n",
    "            if file.endswith('.bz2'):\n",
    "                # Extract bz2 archives to memory\n",
    "                file = bz2.BZ2File(os.path.join(dirpath, file), mode='r')\n",
    "                for line in file:\n",
    "                    tweet = json.loads(line)\n",
    "                    # try/except block in necessary since not all lines are tweets\n",
    "                    try: \n",
    "                        # only retrieve tweets in english\n",
    "                        if tweet['lang']=='en':\n",
    "                            \n",
    "                            # create the fields to be saved\n",
    "                            if tweet['created_at']:\n",
    "                                tweet_date=tweet['created_at']\n",
    "                            else:\n",
    "                                tweet_date=False\n",
    "\n",
    "                            if tweet['id']:\n",
    "                                tweet_id=tweet['id']\n",
    "                            else:\n",
    "                                tweet_id=False\n",
    "\n",
    "                            if tweet['text']:\n",
    "                                tweet_text=tweet['text']\n",
    "                            else:\n",
    "                                tweet_text=False\n",
    "\n",
    "                            if tweet['lang']:\n",
    "                                lang = tweet['lang']\n",
    "                            else:\n",
    "                                lang=False\n",
    "\n",
    "                            if tweet['retweeted']:\n",
    "                                retweet = tweet['retweeted']\n",
    "                            else:\n",
    "                                retweet=False\n",
    "\n",
    "                            if tweet['entities']['urls']:\n",
    "                                tweet_url = True\n",
    "                            else: \n",
    "                                tweet_url = False\n",
    "\n",
    "                            if tweet['in_reply_to_screen_name']:\n",
    "                                tweet_reply = True\n",
    "                            else:\n",
    "                                tweet_reply = False\n",
    "\n",
    "\n",
    "                            hashes = tweet['entities']['hashtags']\n",
    "                            user_name = tweet['user']['name']\n",
    "                            screen_name = tweet['user']['screen_name']\n",
    "                            user_verified = tweet['user']['verified']\n",
    "                            user_lang = tweet['user']['lang']\n",
    "\n",
    "                            # use a dictionary for faster processing\n",
    "                            tweet_dict[i] = [tweet_date,tweet_id,tweet_text,lang,retweet,tweet_url, tweet_reply, \n",
    "                                             hashes, user_name, screen_name, user_verified, user_lang]\n",
    "                            i += 1\n",
    "                            count_tweets += 1\n",
    "                        \n",
    "                    except KeyError:\n",
    "                        continue\n",
    "           \n",
    "    # save df and print processing time\n",
    "    df = pd.DataFrame.from_dict(tweet_dict, orient='index', columns=columns)\n",
    "    df.to_csv(outfile + '.csv')\n",
    "    end_time = datetime.now()\n",
    "    print('Total time to run:', end_time-begin_time)\n",
    "    print('Shape of DataFrame:', df.shape)\n",
    "    return df                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete! Total time: 0:00:09.392108\n"
     ]
    }
   ],
   "source": [
    "process_tar_file('tar_files/twitter-2018-07-31.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_files_list = ['twitter-2018-07-02.tar', 'twitter-2018-07-03(1).tar', 'twitter-2018-07-11.tar', \n",
    "                  'twitter-2018-07-12.tar', 'twitter-2018-07-13.tar', 'twitter-2018-07-14.tar',\n",
    "                  'twitter-2018-07-15.tar', 'twitter-2018-07-16.tar', 'twitter-2018-07-17.tar',\n",
    "                  'twitter-2018-07-18.tar', 'twitter-2018-07-19.tar', 'twitter-2018-07-20.tar',\n",
    "                  'twitter-2018-07-21.tar', 'twitter-2018-07-22.tar', 'twitter-2018-07-23.tar',\n",
    "                  'twitter-2018-07-24.tar', 'twitter-2018-07-25.tar', 'twitter-2018-07-26.tar',\n",
    "                  'twitter-2018-07-27(1).tar', 'twitter-2018-07-28.tar', 'twitter-2018-07-29.tar',\n",
    "                  'twitter-2018-07-30.tar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_files_list = ['twitter-2018-07-26.tar',\n",
    "                  'twitter-2018-07-27(1).tar', 'twitter-2018-07-28.tar', 'twitter-2018-07-29.tar',\n",
    "                  'twitter-2018-07-30.tar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete! Total time: 0:02:29.421206\n",
      "Processing complete! Total time: 0:00:24.584450\n",
      "Processing complete! Total time: 0:00:34.282709\n",
      "Processing complete! Total time: 0:00:13.067030\n",
      "Processing complete! Total time: 0:00:12.708246\n"
     ]
    }
   ],
   "source": [
    "for i in tar_files_list:\n",
    "    process_tar_file('tar_files/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1043571\n",
      "----------\n",
      ">>   currently searching 2018/07/02\\23\n",
      "Total time to run: 0:15:31.396606\n",
      "Shape of DataFrame: (1080494, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_reply</th>\n",
       "      <th>hashes</th>\n",
       "      <th>user_name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Jul 02 06:30:00 +0000 2018</td>\n",
       "      <td>1013671111194603520</td>\n",
       "      <td>RT @ThaLuckeyJr: ya im dtf\\n\\nd- down\\nt- to\\n...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Bee 🦕</td>\n",
       "      <td>bee_onkaa</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Jul 02 06:30:00 +0000 2018</td>\n",
       "      <td>1013671111194599425</td>\n",
       "      <td>RT @TradizionLarry: Taboo Brother Family https...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>.</td>\n",
       "      <td>Roseyrose98</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Jul 02 06:30:00 +0000 2018</td>\n",
       "      <td>1013671111165468672</td>\n",
       "      <td>RT @tribelaw: Among the first cases the Court ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>rt</td>\n",
       "      <td>rtorres</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Jul 02 06:30:00 +0000 2018</td>\n",
       "      <td>1013671111194750976</td>\n",
       "      <td>I’m doing everything I can for my boyfriend, f...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Khaila Ann Vargas</td>\n",
       "      <td>KhailaAnnV</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Jul 02 06:30:00 +0000 2018</td>\n",
       "      <td>1013671111165296640</td>\n",
       "      <td>Get Propecia now to forget the male pattern ha...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Marvin</td>\n",
       "      <td>Marvin64372558</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080489</th>\n",
       "      <td>Tue Jul 03 05:59:59 +0000 2018</td>\n",
       "      <td>1014025945106272256</td>\n",
       "      <td>RT @PopTartsUS: Things you shouldn’t put on yo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Zixxorb (Alex)</td>\n",
       "      <td>Zixxorb</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080490</th>\n",
       "      <td>Tue Jul 03 05:59:59 +0000 2018</td>\n",
       "      <td>1014025945118896129</td>\n",
       "      <td>Punish the pussy and give it a kiss 😘</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>pocahonta$ 💓</td>\n",
       "      <td>chiiink_</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080491</th>\n",
       "      <td>Tue Jul 03 05:59:59 +0000 2018</td>\n",
       "      <td>1014025945127190528</td>\n",
       "      <td>RT @jaycritch: You can’t Finesse a Finesser DUMMY</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>A</td>\n",
       "      <td>asiadenn_</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080492</th>\n",
       "      <td>Tue Jul 03 05:59:59 +0000 2018</td>\n",
       "      <td>1014025945093758976</td>\n",
       "      <td>Followed this guy on insta I used to talk to s...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tierra</td>\n",
       "      <td>Burnziespizza88</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080493</th>\n",
       "      <td>Tue Jul 03 05:59:59 +0000 2018</td>\n",
       "      <td>1014025945114726402</td>\n",
       "      <td>Found a Transponder Snail!\\nLuffy's Grizzly Ma...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'TreCru', 'indices': [100, 107]}]</td>\n",
       "      <td>Georgei</td>\n",
       "      <td>Georgei79590640</td>\n",
       "      <td>False</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080494 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             tweet_date             tweet_id  \\\n",
       "0        Mon Jul 02 06:30:00 +0000 2018  1013671111194603520   \n",
       "1        Mon Jul 02 06:30:00 +0000 2018  1013671111194599425   \n",
       "2        Mon Jul 02 06:30:00 +0000 2018  1013671111165468672   \n",
       "3        Mon Jul 02 06:30:00 +0000 2018  1013671111194750976   \n",
       "4        Mon Jul 02 06:30:00 +0000 2018  1013671111165296640   \n",
       "...                                 ...                  ...   \n",
       "1080489  Tue Jul 03 05:59:59 +0000 2018  1014025945106272256   \n",
       "1080490  Tue Jul 03 05:59:59 +0000 2018  1014025945118896129   \n",
       "1080491  Tue Jul 03 05:59:59 +0000 2018  1014025945127190528   \n",
       "1080492  Tue Jul 03 05:59:59 +0000 2018  1014025945093758976   \n",
       "1080493  Tue Jul 03 05:59:59 +0000 2018  1014025945114726402   \n",
       "\n",
       "                                                tweet_text lang  retweet  \\\n",
       "0        RT @ThaLuckeyJr: ya im dtf\\n\\nd- down\\nt- to\\n...   en    False   \n",
       "1        RT @TradizionLarry: Taboo Brother Family https...   en    False   \n",
       "2        RT @tribelaw: Among the first cases the Court ...   en    False   \n",
       "3        I’m doing everything I can for my boyfriend, f...   en    False   \n",
       "4        Get Propecia now to forget the male pattern ha...   en    False   \n",
       "...                                                    ...  ...      ...   \n",
       "1080489  RT @PopTartsUS: Things you shouldn’t put on yo...   en    False   \n",
       "1080490              Punish the pussy and give it a kiss 😘   en    False   \n",
       "1080491  RT @jaycritch: You can’t Finesse a Finesser DUMMY   en    False   \n",
       "1080492  Followed this guy on insta I used to talk to s...   en    False   \n",
       "1080493  Found a Transponder Snail!\\nLuffy's Grizzly Ma...   en    False   \n",
       "\n",
       "         tweet_url  tweet_reply                                       hashes  \\\n",
       "0            False        False                                           []   \n",
       "1            False        False                                           []   \n",
       "2            False        False                                           []   \n",
       "3            False        False                                           []   \n",
       "4             True        False                                           []   \n",
       "...            ...          ...                                          ...   \n",
       "1080489      False        False                                           []   \n",
       "1080490      False        False                                           []   \n",
       "1080491      False        False                                           []   \n",
       "1080492       True        False                                           []   \n",
       "1080493       True        False  [{'text': 'TreCru', 'indices': [100, 107]}]   \n",
       "\n",
       "                 user_name      screen_name  user_verified user_lang  \n",
       "0                    Bee 🦕        bee_onkaa          False        en  \n",
       "1                        .      Roseyrose98          False        en  \n",
       "2                       rt          rtorres          False        en  \n",
       "3        Khaila Ann Vargas       KhailaAnnV          False        en  \n",
       "4                   Marvin   Marvin64372558          False        en  \n",
       "...                    ...              ...            ...       ...  \n",
       "1080489     Zixxorb (Alex)          Zixxorb          False        en  \n",
       "1080490       pocahonta$ 💓         chiiink_          False        en  \n",
       "1080491                  A        asiadenn_          False        en  \n",
       "1080492             Tierra  Burnziespizza88          False        en  \n",
       "1080493            Georgei  Georgei79590640          False        de  \n",
       "\n",
       "[1080494 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_json('2018/07/02', 'twitter_stream_csvs/july_two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 898484\n",
      "----------\n",
      ">>   currently searching 2018/07/03\\20\n",
      "Total time to run: 0:12:11.364803\n",
      "Shape of DataFrame: (902436, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/03', 'twitter_stream_csvs/july_three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 577102\n",
      "----------\n",
      ">>   currently searching 2018/07/11\\23\n",
      "Total time to run: 0:07:32.826890\n",
      "Shape of DataFrame: (615851, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/11', 'twitter_stream_csvs/july_eleven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1048445\n",
      "----------\n",
      ">>   currently searching 2018/07/12\\23\n",
      "Total time to run: 0:14:41.606085\n",
      "Shape of DataFrame: (1086872, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/12', 'twitter_stream_csvs/july_twelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1046414\n",
      "----------\n",
      ">>   currently searching 2018/07/13\\23\n",
      "Total time to run: 0:14:49.134354\n",
      "Shape of DataFrame: (1085444, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/13', 'twitter_stream_csvs/july_thirteen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 969644\n",
      "----------\n",
      ">>   currently searching 2018/07/14\\23\n",
      "Total time to run: 0:13:55.830673\n",
      "Shape of DataFrame: (1007251, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/14', 'twitter_stream_csvs/july_fourteen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1034331\n",
      "----------\n",
      ">>   currently searching 2018/07/15\\23\n",
      "Total time to run: 0:14:56.389021\n",
      "Shape of DataFrame: (1071798, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/15', 'twitter_stream_csvs/july_fifteen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1101203\n",
      "----------\n",
      ">>   currently searching 2018/07/16\\23\n",
      "Total time to run: 0:14:52.053455\n",
      "Shape of DataFrame: (1141345, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/16', 'twitter_stream_csvs/july_sixteen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1074512\n",
      "----------\n",
      ">>   currently searching 2018/07/17\\23\n",
      "Total time to run: 0:14:16.684114\n",
      "Shape of DataFrame: (1113110, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/17', 'twitter_stream_csvs/july_seventeen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1045359\n",
      "----------\n",
      ">>   currently searching 2018/07/18\\23\n",
      "Total time to run: 0:13:56.929638\n",
      "Shape of DataFrame: (1083442, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/18', 'twitter_stream_csvs/july_eighteen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1028649\n",
      "----------\n",
      ">>   currently searching 2018/07/19\\23\n",
      "Total time to run: 0:14:03.651578\n",
      "Shape of DataFrame: (1067000, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/19', 'twitter_stream_csvs/july_nineteen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1001435\n",
      "----------\n",
      ">>   currently searching 2018/07/20\\23\n",
      "Total time to run: 0:13:59.503508\n",
      "Shape of DataFrame: (1037888, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/20', 'twitter_stream_csvs/july_twenty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 936878\n",
      "----------\n",
      ">>   currently searching 2018/07/21\\23\n",
      "Total time to run: 0:13:44.143779\n",
      "Shape of DataFrame: (974163, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/21', 'twitter_stream_csvs/july_twentyone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 982280\n",
      "----------\n",
      ">>   currently searching 2018/07/22\\23\n",
      "Total time to run: 0:14:08.711941\n",
      "Shape of DataFrame: (1024820, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/22', 'twitter_stream_csvs/july_twentytwo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1076589\n",
      "----------\n",
      ">>   currently searching 2018/07/23\\23\n",
      "Total time to run: 0:14:40.675356\n",
      "Shape of DataFrame: (1114234, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/23', 'twitter_stream_csvs/july_twentythree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1050635\n",
      "----------\n",
      ">>   currently searching 2018/07/24\\23\n",
      "Total time to run: 0:14:23.844904\n",
      "Shape of DataFrame: (1088423, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/24', 'twitter_stream_csvs/july_twentyfour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1017148\n",
      "----------\n",
      ">>   currently searching 2018/07/25\\23\n",
      "Total time to run: 0:14:21.065782\n",
      "Shape of DataFrame: (1053863, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/25', 'twitter_stream_csvs/july_twentyfive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 991858\n",
      "----------\n",
      ">>   currently searching 2018/07/26\\23\n",
      "Total time to run: 0:13:55.674786\n",
      "Shape of DataFrame: (1028079, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/26', 'twitter_stream_csvs/july_twentysix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 1222842\n",
      "----------\n",
      ">>   currently searching 2018/07/27\\23\n",
      "Total time to run: 0:16:35.034813\n",
      "Shape of DataFrame: (1257309, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/27', 'twitter_stream_csvs/july_twentyseven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 885653\n",
      "----------\n",
      ">>   currently searching 2018/07/28\\23\n",
      "Total time to run: 0:13:59.093294\n",
      "Shape of DataFrame: (920218, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/28', 'twitter_stream_csvs/july_twentyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 917318\n",
      "----------\n",
      ">>   currently searching 2018/07/29\\23\n",
      "Total time to run: 0:13:49.191035\n",
      "Shape of DataFrame: (951774, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/29', 'twitter_stream_csvs/july_twentynine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 976493\n",
      "----------\n",
      ">>   currently searching 2018/07/30\\23\n",
      "Total time to run: 0:14:07.206761\n",
      "Shape of DataFrame: (1013266, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/30', 'twitter_stream_csvs/july_thirty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>   tweets: 988675\n",
      "----------\n",
      ">>   currently searching 2018/07/31\\23\n",
      "Total time to run: 0:14:38.263325\n",
      "Shape of DataFrame: (1024708, 12)\n"
     ]
    }
   ],
   "source": [
    "df = process_json('2018/07/31', 'twitter_stream_csvs/july_thirtyone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_reply</th>\n",
       "      <th>hashes</th>\n",
       "      <th>user_name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359276064768</td>\n",
       "      <td>RT @ArchanaArchuu: Too many arguments will cau...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'argument', 'indices': [76, 85]}]</td>\n",
       "      <td>ஏசுதாஸ்™</td>\n",
       "      <td>yesudoss_officl</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359305392128</td>\n",
       "      <td>RT @irina3529: Happy new week... 🌻🐾🍀🐾🌻 https:/...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[투표소手개표] '양심과 상식'이 일상이 되는 나라</td>\n",
       "      <td>pwbr000</td>\n",
       "      <td>False</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359288823808</td>\n",
       "      <td>i’m in the mood to go for a long ride but ever...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>mae</td>\n",
       "      <td>maeaes</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359276126208</td>\n",
       "      <td>RT @nbcsandiego: Out of all the pitches thrown...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Padres', 'indices': [59, 66]}]</td>\n",
       "      <td>WilliamBriggsDDS</td>\n",
       "      <td>WilliaBriggsDDS</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359305601025</td>\n",
       "      <td>Don't sleep on your dreams. You have the capac...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Nomfundo Khambule</td>\n",
       "      <td>NomfundoThePoet</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet_date             tweet_id  \\\n",
       "0  Tue Jul 31 06:30:00 +0000 2018  1024180359276064768   \n",
       "1  Tue Jul 31 06:30:00 +0000 2018  1024180359305392128   \n",
       "2  Tue Jul 31 06:30:00 +0000 2018  1024180359288823808   \n",
       "3  Tue Jul 31 06:30:00 +0000 2018  1024180359276126208   \n",
       "4  Tue Jul 31 06:30:00 +0000 2018  1024180359305601025   \n",
       "\n",
       "                                          tweet_text lang  retweet  tweet_url  \\\n",
       "0  RT @ArchanaArchuu: Too many arguments will cau...   en    False      False   \n",
       "1  RT @irina3529: Happy new week... 🌻🐾🍀🐾🌻 https:/...   en    False      False   \n",
       "2  i’m in the mood to go for a long ride but ever...   en    False      False   \n",
       "3  RT @nbcsandiego: Out of all the pitches thrown...   en    False      False   \n",
       "4  Don't sleep on your dreams. You have the capac...   en    False      False   \n",
       "\n",
       "   tweet_reply                                       hashes  \\\n",
       "0        False  [{'text': 'argument', 'indices': [76, 85]}]   \n",
       "1        False                                           []   \n",
       "2        False                                           []   \n",
       "3        False    [{'text': 'Padres', 'indices': [59, 66]}]   \n",
       "4        False                                           []   \n",
       "\n",
       "                      user_name      screen_name  user_verified user_lang  \n",
       "0                      ஏசுதாஸ்™  yesudoss_officl          False        en  \n",
       "1  [투표소手개표] '양심과 상식'이 일상이 되는 나라          pwbr000          False        ko  \n",
       "2                           mae           maeaes          False        en  \n",
       "3              WilliamBriggsDDS  WilliaBriggsDDS          False        en  \n",
       "4             Nomfundo Khambule  NomfundoThePoet          False        en  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing regex filtering for finance-related tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this regex will match any string that begin with a \"$\" and has lower or upper case letter immediately following it\n",
    "pattern = re.compile(r'(\\$[A-Za-z]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @ArchanaArchuu: Too many arguments will cause a relationship to die. \\nNo #argument however means the relationship is already dead.\\n\\n#Sha…'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for i in range(len(df['tweet_text'])):\n",
    "    matches.append(re.findall(pattern, df['tweet_text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_reply</th>\n",
       "      <th>hashes</th>\n",
       "      <th>user_name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_lang</th>\n",
       "      <th>regex_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359276064768</td>\n",
       "      <td>RT @ArchanaArchuu: Too many arguments will cau...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'argument', 'indices': [76, 85]}]</td>\n",
       "      <td>ஏசுதாஸ்™</td>\n",
       "      <td>yesudoss_officl</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359305392128</td>\n",
       "      <td>RT @irina3529: Happy new week... 🌻🐾🍀🐾🌻 https:/...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[투표소手개표] '양심과 상식'이 일상이 되는 나라</td>\n",
       "      <td>pwbr000</td>\n",
       "      <td>False</td>\n",
       "      <td>ko</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359288823808</td>\n",
       "      <td>i’m in the mood to go for a long ride but ever...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>mae</td>\n",
       "      <td>maeaes</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359276126208</td>\n",
       "      <td>RT @nbcsandiego: Out of all the pitches thrown...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Padres', 'indices': [59, 66]}]</td>\n",
       "      <td>WilliamBriggsDDS</td>\n",
       "      <td>WilliaBriggsDDS</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Jul 31 06:30:00 +0000 2018</td>\n",
       "      <td>1024180359305601025</td>\n",
       "      <td>Don't sleep on your dreams. You have the capac...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Nomfundo Khambule</td>\n",
       "      <td>NomfundoThePoet</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet_date             tweet_id  \\\n",
       "0  Tue Jul 31 06:30:00 +0000 2018  1024180359276064768   \n",
       "1  Tue Jul 31 06:30:00 +0000 2018  1024180359305392128   \n",
       "2  Tue Jul 31 06:30:00 +0000 2018  1024180359288823808   \n",
       "3  Tue Jul 31 06:30:00 +0000 2018  1024180359276126208   \n",
       "4  Tue Jul 31 06:30:00 +0000 2018  1024180359305601025   \n",
       "\n",
       "                                          tweet_text lang  retweet  tweet_url  \\\n",
       "0  RT @ArchanaArchuu: Too many arguments will cau...   en    False      False   \n",
       "1  RT @irina3529: Happy new week... 🌻🐾🍀🐾🌻 https:/...   en    False      False   \n",
       "2  i’m in the mood to go for a long ride but ever...   en    False      False   \n",
       "3  RT @nbcsandiego: Out of all the pitches thrown...   en    False      False   \n",
       "4  Don't sleep on your dreams. You have the capac...   en    False      False   \n",
       "\n",
       "   tweet_reply                                       hashes  \\\n",
       "0        False  [{'text': 'argument', 'indices': [76, 85]}]   \n",
       "1        False                                           []   \n",
       "2        False                                           []   \n",
       "3        False    [{'text': 'Padres', 'indices': [59, 66]}]   \n",
       "4        False                                           []   \n",
       "\n",
       "                      user_name      screen_name  user_verified user_lang  \\\n",
       "0                      ஏசுதாஸ்™  yesudoss_officl          False        en   \n",
       "1  [투표소手개표] '양심과 상식'이 일상이 되는 나라          pwbr000          False        ko   \n",
       "2                           mae           maeaes          False        en   \n",
       "3              WilliamBriggsDDS  WilliaBriggsDDS          False        en   \n",
       "4             Nomfundo Khambule  NomfundoThePoet          False        en   \n",
       "\n",
       "  regex_matches  \n",
       "0            []  \n",
       "1            []  \n",
       "2            []  \n",
       "3            []  \n",
       "4            []  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy['regex_matches'] = matches\n",
    "copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1723, 13)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tweets = copy[copy.regex_matches.apply(len) > 0]\n",
    "regex_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_reply</th>\n",
       "      <th>hashes</th>\n",
       "      <th>user_name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_lang</th>\n",
       "      <th>regex_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533191</th>\n",
       "      <td>Tue Jul 31 19:19:25 +0000 2018</td>\n",
       "      <td>1024373989328805889</td>\n",
       "      <td>Slb $SLB Position Has Lifted by Fulton Breakef...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>US Index Live</td>\n",
       "      <td>usindexlive</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[$SLB, $BMY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263223</th>\n",
       "      <td>Tue Jul 31 14:10:04 +0000 2018</td>\n",
       "      <td>1024296138839605248</td>\n",
       "      <td>How cool $GOOGL 1203 would mark 7% decline als...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>PrecisionTrade365</td>\n",
       "      <td>Kris_tin27</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[$GOOGL, $Aapl]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tweet_date             tweet_id  \\\n",
       "533191  Tue Jul 31 19:19:25 +0000 2018  1024373989328805889   \n",
       "263223  Tue Jul 31 14:10:04 +0000 2018  1024296138839605248   \n",
       "\n",
       "                                               tweet_text lang  retweet  \\\n",
       "533191  Slb $SLB Position Has Lifted by Fulton Breakef...   en    False   \n",
       "263223  How cool $GOOGL 1203 would mark 7% decline als...   en    False   \n",
       "\n",
       "        tweet_url  tweet_reply hashes          user_name  screen_name  \\\n",
       "533191       True        False     []      US Index Live  usindexlive   \n",
       "263223      False        False     []  PrecisionTrade365   Kris_tin27   \n",
       "\n",
       "        user_verified user_lang    regex_matches  \n",
       "533191          False        en     [$SLB, $BMY]  \n",
       "263223          False        en  [$GOOGL, $Aapl]  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tweets.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aye bruh 10 dollars is 10 dollars. $DeShawnBloomfield'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tweets['tweet_text'].loc[548733]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use regex to filter each day's tweets and save to new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to only retrieve the tweets that contain (or likely contain) a cashtag\n",
    "def regex_filter_for_cashtag(input_file, input_path='twitter_stream_csvs/', \n",
    "                             output_path='finance_twitter_stream_csvs/finance_'):\n",
    "    \n",
    "    # load file and create the pattern, which search for a cashtag\n",
    "    df = pd.read_csv(input_path + input_file + '.csv')\n",
    "    pattern = re.compile(r'(\\$[A-Za-z]+)')\n",
    "\n",
    "    # find all regex matches and return them in a list\n",
    "    matches = []\n",
    "    for i in range(len(df['tweet_text'])):\n",
    "        matches.append(re.findall(pattern, df['tweet_text'][i]))\n",
    "    \n",
    "    # add matches to the DataFrame\n",
    "    df['regex_matches'] = matches\n",
    "\n",
    "    # only keep tweets where there was a regex match\n",
    "    regex_tweets = df[df.regex_matches.apply(len) > 0]\n",
    "\n",
    "    # save the new df\n",
    "    regex_tweets.to_csv(output_path + input_file + '.csv')\n",
    "    print('File saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved!\n"
     ]
    }
   ],
   "source": [
    "regex_filter_for_cashtag(input_file='july_three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_process = ['july_eighteen', 'july_eleven', 'july_fifteen', 'july_fourteen', 'july_nineteen', 'july_seventeen',\n",
    "                    'july_sixteen', 'july_thirteen', 'july_thirty', 'july_thirtyone', 'july_twelve', 'july_twenty',\n",
    "                    'july_twentyeight', 'july_twentyfive', 'july_twentyfour', 'july_twentynine', 'july_twentyone',\n",
    "                    'july_twentyseven', 'july_twentysix', 'july_twentythree', 'july_twentytwo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n",
      "File saved!\n"
     ]
    }
   ],
   "source": [
    "for i in files_to_process:\n",
    "    regex_filter_for_cashtag(input_file=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved!\n"
     ]
    }
   ],
   "source": [
    "regex_filter_for_cashtag(input_file='twitter_stream_with_name', input_path='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tweet_date', 'tweet_id', 'tweet_text', 'lang', 'retweet',\n",
       "       'tweet_url', 'tweet_reply', 'hashes', 'user_name', 'screen_name',\n",
       "       'user_verified', 'user_lang', 'regex_matches'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine each day's file into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory to the folder with the files and find all files with .csv\n",
    "extension = 'csv'\n",
    "# os.chdir('finance_twitter_stream_csvs')\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the files into one\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "combined_csv.to_csv('july_finance_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_reply</th>\n",
       "      <th>hashes</th>\n",
       "      <th>user_name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_lang</th>\n",
       "      <th>regex_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>Wed Jul 18 06:30:20 +0000 2018</td>\n",
       "      <td>1019469400934703104</td>\n",
       "      <td>RT @tradingroomapp: #Bitcoin what next?\\n\\n$BT...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Bitcoin', 'indices': [20, 28]}]</td>\n",
       "      <td>Coin [shreds every coin] Shredder</td>\n",
       "      <td>ShredderSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>['$BTC']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1316</td>\n",
       "      <td>1316</td>\n",
       "      <td>Wed Jul 18 06:32:16 +0000 2018</td>\n",
       "      <td>1019469887457103872</td>\n",
       "      <td>Fidus Investment Corp $FDUS Receives Consensus...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ticker Report</td>\n",
       "      <td>TickerReport</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>['$FDUS']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1340</td>\n",
       "      <td>1340</td>\n",
       "      <td>Wed Jul 18 06:32:19 +0000 2018</td>\n",
       "      <td>1019469900061052928</td>\n",
       "      <td>The Coca-Cola $KO to Release Quarterly Earning...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ticker Report</td>\n",
       "      <td>TickerReport</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>['$KO']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1350</td>\n",
       "      <td>1350</td>\n",
       "      <td>Wed Jul 18 06:32:20 +0000 2018</td>\n",
       "      <td>1019469904217542656</td>\n",
       "      <td>Home Bancshares Inc Forecasted to Post Q3 2018...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'markets', 'indices': [105, 113]}]</td>\n",
       "      <td>IRA Market Report</td>\n",
       "      <td>IRAMarketReport</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>['$HOMB']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1616</td>\n",
       "      <td>1616</td>\n",
       "      <td>Wed Jul 18 06:32:53 +0000 2018</td>\n",
       "      <td>1019470042650546179</td>\n",
       "      <td>Intec Pharma Ltd $NTEC Given Consensus Rating ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Macon Daily</td>\n",
       "      <td>macondailynews</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>['$NTEC']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                      tweet_date  \\\n",
       "0         239           239  Wed Jul 18 06:30:20 +0000 2018   \n",
       "1        1316          1316  Wed Jul 18 06:32:16 +0000 2018   \n",
       "2        1340          1340  Wed Jul 18 06:32:19 +0000 2018   \n",
       "3        1350          1350  Wed Jul 18 06:32:20 +0000 2018   \n",
       "4        1616          1616  Wed Jul 18 06:32:53 +0000 2018   \n",
       "\n",
       "              tweet_id                                         tweet_text  \\\n",
       "0  1019469400934703104  RT @tradingroomapp: #Bitcoin what next?\\n\\n$BT...   \n",
       "1  1019469887457103872  Fidus Investment Corp $FDUS Receives Consensus...   \n",
       "2  1019469900061052928  The Coca-Cola $KO to Release Quarterly Earning...   \n",
       "3  1019469904217542656  Home Bancshares Inc Forecasted to Post Q3 2018...   \n",
       "4  1019470042650546179  Intec Pharma Ltd $NTEC Given Consensus Rating ...   \n",
       "\n",
       "  lang  retweet  tweet_url  tweet_reply  \\\n",
       "0   en    False      False        False   \n",
       "1   en    False       True        False   \n",
       "2   en    False       True        False   \n",
       "3   en    False       True        False   \n",
       "4   en    False       True        False   \n",
       "\n",
       "                                         hashes  \\\n",
       "0    [{'text': 'Bitcoin', 'indices': [20, 28]}]   \n",
       "1                                            []   \n",
       "2                                            []   \n",
       "3  [{'text': 'markets', 'indices': [105, 113]}]   \n",
       "4                                            []   \n",
       "\n",
       "                           user_name      screen_name  user_verified  \\\n",
       "0  Coin [shreds every coin] Shredder  ShredderSupport          False   \n",
       "1                      Ticker Report     TickerReport          False   \n",
       "2                      Ticker Report     TickerReport          False   \n",
       "3                  IRA Market Report  IRAMarketReport          False   \n",
       "4                        Macon Daily   macondailynews          False   \n",
       "\n",
       "  user_lang regex_matches  \n",
       "0        en      ['$BTC']  \n",
       "1        en     ['$FDUS']  \n",
       "2        en       ['$KO']  \n",
       "3        en     ['$HOMB']  \n",
       "4        en     ['$NTEC']  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39385, 15)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I end with a DataFrame that has nearly 40,000 tweets, which will need to be cleaned and precessed to remove tweets that are not actually finance-related and to prepare the text so that it can be used by a machine learning algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
